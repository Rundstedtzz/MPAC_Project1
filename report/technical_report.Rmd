---
title: "MPAC Project 1 Technical Report"
author: "Crosby Byrnes, Ricky Sun, Suzy Ryckman, and Cheryl Jiao"
date: "`r format(Sys.Date(), '%A %b %Y')`"
output: 
  html_document:
    theme: cosmo
    highlight: haddock
    toc: TRUE
    toc_float: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r load-packages, echo = FALSE, message = FALSE, warning = FALSE}
library(readr)
library(tidytext)
library(stringr)
library(tidyverse) 
library(skimr)
library(robotstxt)
library(rvest)
library(SnowballC)
library(dplyr)
library(janitor)
library(janeaustenr)
library(wordcloud)
library(tm)
library(here)
library(RColorBrewer)

remotes::install_github("wilkelab/ggridges")
library(ggridges)
library(forcats)

library(ggplot2)
library(dplyr)
library(viridis)
library(hrbrthemes)
devtools::install_github("ropensci/plotly")
library(plotly)

library(igraph)
library(ggraph)
library(widyr)
library(tidyr)
```

```{r load-data}
parole_data <- read_csv("https://raw.githubusercontent.com/Rundstedtzz/MPAC_Project1/main/data/proquest_1.csv")

parole_text_1 <- read.delim("https://raw.githubusercontent.com/Rundstedtzz/MPAC_Project1/main/data/proquest_2.txt", header = TRUE)
colnames(parole_text_1)[1] <- "id"
```

```{r set-up-pattern}
pattern <- paste(parole_data$StoreId, collapse = "|") # all possible patterns

parole_text_1$StoreId <- as.numeric(str_extract(string = parole_text_1$id, pattern = pattern))

parole_text_article <- parole_text_1 %>% fill(StoreId)

parole_text_article_df <- left_join(parole_text_article, 
                           parole_data,
                           by = "StoreId")

colnames(parole_text_article_df)[1] <- "text"
```

```{r delete-unnecessary-texts}
parole_sub <- parole_text_article_df[-str_which(parole_text_article_df$text, pattern = "ProQuest document ID:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Publication info:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "https:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Author:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Abstract:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Subject:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Location:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Company / organization:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Title:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Publication title:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Publication year:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Publication date:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Publication subject:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "First page:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Publisher:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Place of publication:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Country of publication:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Language of publication:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "ISSN:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Source type:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Document type:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Copyright:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Last updated:"),]
parole_sub <- parole_sub[-str_which(parole_sub$text, pattern = "Database:"),]
parole_sub <- parole_sub[-(str_which(parole_sub$text, pattern = "Full text:")-1),]
prepare_sub <- str_which(parole_sub$text, pattern = "Full text:")-1
parole_sub <- parole_sub[-prepare_sub[-1],]
```

```{r attaching-part-of-speech}
parole_sub2 <- parole_sub %>%
  select(text, year, pubtitle) %>%
  unnest_tokens(output = word, input = text) %>%
  anti_join(stop_words) %>%
  mutate(word = tolower(word)) 

parts_of_speech_ad <- parts_of_speech %>%
  filter(pos %in% c("Adjective", "Adverb", "Noun", "Verb"))

parole_sub2 <- parole_sub2 %>%
  left_join(parts_of_speech_ad, by = "word")
```

```{r attaching-sentiments-text}
parole_sentiments <- get_sentiments()
parole_final <- parole_sub2 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_final[is.na(parole_final)] <- "neutral"

#write_csv(parole_final, "parole_final.csv")

parole_sub4 <- parole_sub2 %>%
  group_by(year, pubtitle, word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sentiments <- get_sentiments()
parole_text <- parole_sub4 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_text[is.na(parole_text)] <- "neutral"

parole_sentiments <- get_sentiments()
parole_adj_adv <- parole_sub4 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_adj_adv[is.na(parole_adj_adv)] <- "neutral"
```

```{r attaching-sentiments-text-with-title}
parole_sentiments <- get_sentiments()

parole_sub2 <- parole_sub %>%
  select(text, Title, year, pubtitle) %>%
  unnest_tokens(output = word, input = text) %>%
  anti_join(stop_words) %>%
  mutate(word = tolower(word)) 

parts_of_speech_ad <- parts_of_speech %>%
  filter(pos %in% c("Adjective", "Adverb", "Noun", "Verb"))

parole_sub2 <- parole_sub2 %>%
  left_join(parts_of_speech_ad, by = "word")

parole_sub4 <- parole_sub2 %>%
  group_by(Title, year, pubtitle, word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sentiments <- get_sentiments()
parole_text_title <- parole_sub4 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_text_title[is.na(parole_text_title)] <- "neutral"

```

```{r attaching-sentiments-title}
parole_sub2 <- parole_sub %>%
  select(Title, year, pubtitle) %>%
  distinct(Title, year, pubtitle) %>%
  unnest_tokens(output = word, input = Title) %>%
  anti_join(stop_words) %>%
  mutate(word = tolower(word)) 

parts_of_speech_ad <- parts_of_speech %>%
  filter(pos %in% c("Adjective", "Adverb", "Noun", "Verb"))

parole_sub2 <- parole_sub2 %>%
  left_join(parts_of_speech_ad, by = "word")

parole_sub4 <- parole_sub2 %>%
  group_by(year, pubtitle, word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()


parole_sentiments <- get_sentiments()
parole_title <- parole_sub4 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_title[is.na(parole_title)] <- "neutral"
```

```{r attaching-sentiments-abstract}
parole_sub2 <- parole_sub %>%
  select(Abstract, year, pubtitle) %>%
  distinct(Abstract, year, pubtitle) %>%
  unnest_tokens(output = word, input = Abstract) %>%
  anti_join(stop_words) %>%
  mutate(word = tolower(word)) 

parts_of_speech_ad <- parts_of_speech %>%
  filter(pos %in% c("Adjective", "Adverb", "Noun", "Verb"))

parole_sub2 <- parole_sub2 %>%
  left_join(parts_of_speech_ad, by = "word")

parole_sub4 <- parole_sub2 %>%
  group_by(year, pubtitle, word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sentiments <- get_sentiments()
parole_abstract <- parole_sub4 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_abstract[is.na(parole_abstract)] <- "neutral"
```

## Executive Summary
### Overview
The Maine Prisoner Advocacy Coalition is planning to campaign on behalf of the reinstatement of parole and organize policy action to support the new parole initiative. In working with the MPAC, we used data from three Maine newspapers to evaluate local public perception toward parole by utilizing text analysis.

### The Problem
The bill to reinstate parole in Maine has yet to be signed by the governor. Therefore, the MPAC is planning to campaign on behalf of the bill to increase resident support for the initiative and to assist legislators in drafting an amended bill that will pass once the investigator has been conducted. 
	
### Our Research
Our research of opinion mining categorizes language into positive, negative, or neutral sentiments and generates a series of visualizations to highlight trends. These trends identified by our sentimental analysis will help the MPAC make informed decisions when organizing campaigns so they can maximize saliency to the public. 


### Next Steps
For further research on the public perspective of parole and probation using text analysis, we have the following suggestions. 
- Further analyses can implement stemming to minimize repeatedly counting words of the same stem
- Further application of machine learning techniques to text analysis
- Refinement of word association analysis

### Summary
There are several limitations to our study, primarily that we assume sentiments articulated in the newspaper articles are representative of general public opinion in Maine. However, we believe that our results can give context to some of the public’s reactions to issues around parole. This report can be vital to campaigning strategy and is a great foundation for future research.



## Introduction & Backgrounds
In 1976, Maine was the first state to abolish parole during the antiwar movement. Several states followed Maine’s lead abolishing parole in an effort to move away from indeterminate sentences and increase predictability in punishment. At this time, the goal of incarceration shifted from rehabilitation to punishment as policymakers argued prisoners were not capable of recovery without recidivism. Although in the 1970s the U.S. incarceration rate was comparable to those in Europe and Canada, by the 2010s the United States housed 25% of the world’s prisons. Since the mid1970s, the incarceration rate in America has increased more than fourfold and the United States leads the world in prison population. More specifically, in Maine, the number of people locked up has increased 163% since 1983 and women in prison has increased by 794%. 

In an effort to shift the focus back from punishment to rehabilitation in the judicial system, extensive literature has been published by researchers discussing cultural indicators for criminal behavior, such as the importance of child abuse, poverty, and early exposure to substance abuse, and the positive impact of individual-centered approaches to crime prevention that can be facilitated by community-based approaches. Thus, initiatives to help prevent criminal behavior and reduce the likelihood of recidivism from a community standpoint are essential to reducing the incarceration rate. 

Today, Maine is one of 16 states that doesn’t have parole. Recently however, a bill to restore parole in Maine was passed in the House and Senate to be signed by the governor. The bill ultimately failed in 2021, but an investigation was authorized to delve into the logistics of reinstating parole, the infrastructure needed to support indeterminate sentencing, and the cost-analysis of the revampment of Maine’s judicial system. 

Our community partner for this project, the Maine Prisoner Advocacy Coalition, is planning to campaign on behalf of the reinstatement of parole and organize policy action to support the new parole initiative. In working with the MPAC, we evaluated local public perception toward parole by utilizing text analysis. By using data from three main newspapers, the Portland Press Herald, the Bangor Daily, and the Sun Journal, we aimed to cover the broad spectrum of news coverage across the entirety of Maine and conducted sentimental analysis using R to track perception around parole. We must preface that we are assuming these news sources are representative of public perception and that not only are the opinions of the local communities informed by these local papers but also representative of their opinions. We understand that not everyone in Maine reads the local paper or has the same opinion, but for the purposes of our research we are making generalizations about the local population. Nevertheless, through this process of opinion mining, we categorized language into positive, negative, or neutral sentiments and generated a series of visualizations to highlight trends. Our goal is that our research identifies trends that will help the MPAC make informed decisions when organizing campaigns so they can maximize saliency to the public. 

## Data
The data set was given to us in the form of a ProQuest document. ProQuest is an academic database which is considered as the broadest single research resource in the world. Using help from a researcher at Bates and an advanced search option, we were able to trim down our newspaper search rapidly using filters and limiting the topics by searching “parole” in abstract or “parole” and “probation” in the title for example. Our filtered searches helped us end with 738 newspaper articles focusing on three main Maine newspapers: The Bangor Daily News, The Sun Journal, Portland Press Herald. The dimensions for our data are specific to the question of parole in Maine in between 2000 and the present where we focused on the sentiment ( negative/ positive/ neutral). 

## Methods
Once we retrieved the data, we started cleaning it using multiple methods. We needed to use stopwords (which removes small words such as “a”, “the”, “at”), unnesting (Nesting creates a list-column of data frames; unnesting flattens it back out into regular columns, anti-join (anti-joining the stopwords and the data), part-of-speech(). Such tools gave us more room to analyze sentiments around parole and how the newspapers expressed themselves concerning this topic. As a group we decided to focus on data going from the present day all the way back to 2000. While cleaning our data, separating words was an important part of our process when looking at whether a word is a noun, adjective or an adverb.
Once the data had been fully cleaned, we then started our Text Analysis using R Studio as well as R Markdown and R Shiny. After coding, we were able to create wordclouds looking at word frequencies and how much value a word has depending on its color. Secondly, we made bar plots looking at negative adverbs/ adjectives in Maine news concerning parole which gave us some interesting feedback. Our analysis became more detailed once we met with Amy Douglass (Psychology Professor at Bates College)  as well as Jan Collins who works for the Maine Prison Advocacy Coalition Group. The situation on parole in Maine was eventually more clear to us which helped us narrow down our focus and what visualisations we felt were vital to our research. The next step in our analysis was exploring sentiments through adults versus juveniles in Maine. We have finally created word associations which focuses on relations between words and the amout of times they are linked. 

## Results  

### Part I - Preliminary analysis

#### Word-cloud for most frequent words {.tabset}

After we cleaned out data, we first took a look at the frequencies of words, in particular, most frequent negative and positive adjectives and adverbs. From the word clouds, we can see that for negative adjectives and adverbs, “guilty”, “gross”, “killing”, and “unlawful” are the most frequently appeared adjectives and adverbs, while for positive ones, they are “superior”, “positive”, “ significant”, “fair”, “free” and so on. We can get an overview idea of how the newspaper articles depict parole from positive or negative perspectives in Maine. 

##### Most frequent negative words
```{r word-cloud-negative}
parole_sub_x <- parole_sub2 %>%
  group_by(word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sentiments <- get_sentiments()

parole_abstract_wordcloud <- parole_sub_x %>%
  left_join(parole_sentiments, by = "word") 

parole_abstract_wordcloud[is.na(parole_abstract_wordcloud)] <- "neutral"

parole_abstract_wordcloud <- parole_abstract_wordcloud %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(sentiment == "negative") 
  
set.seed(1234)
wordcloud(words = parole_abstract_wordcloud$word, freq = parole_abstract_wordcloud$count, min.freq = 2,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

##### Most frequent negative words
```{r word-cloud-positive}
parole_sub_x <- parole_sub2 %>%
  group_by(word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sentiments <- get_sentiments()

parole_abstract_wordcloud <- parole_sub_x %>%
  left_join(parole_sentiments, by = "word") 

parole_abstract_wordcloud[is.na(parole_abstract_wordcloud)] <- "neutral"

parole_abstract_wordcloud <- parole_abstract_wordcloud %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(sentiment == "positive") 
  
set.seed(1234)
wordcloud(words = parole_abstract_wordcloud$word, freq = parole_abstract_wordcloud$count, min.freq = 2,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

### Part II - Sentiment analysis

#### R-Shiny bar plot for most frequent words
The word clouds could be limited and we cannot see the actual counts of words. In order to make viewing most frequent words more convenient, we created a R-shiny bar plot, which can be varied by different criteria, such as sentiments (positive, negative, neutral), part of speech (noun, adjective, adverb), year (from 2000 to 2022), how many top words to show, and press (Sun Journal, Bangor Daily News, Portland Press Herald). Here is the link to the published R-shiny app: 
https://3fjgps-qifeng-sun.shinyapps.io/Interactive_bar_parole/

<br/>

#### Sentiments over year

Next, we move on to our sentiment analysis to see what sentiments are behind those most frequent words. In general, parole is talked about in a cyclical pattern, which could be in line with some national level parole campaigns or parole reinstatement discussion in other states. In general, we can see that the attitudes towards parole in Maine media from the three newspapers we select, is more negative than positive. 
```{r general, fig.align = 'left'}
variation_data2 <- parole_adj_adv %>%
  ungroup() %>%
  group_by(sentiment, year) %>%
  summarise(count_total = sum(count)) %>%
  filter(sentiment %in% c("positive", "negative")) %>%
  arrange(year)

plot2 <- variation_data2 %>% 
  ggplot( aes(x=year, y=count_total, fill=sentiment, text=sentiment)) +
    geom_area(alpha = 0.6) +
    scale_fill_viridis(discrete = TRUE) +
    theme() +
    ggtitle("Sentiments Over the Course of 20 years") +
    theme_ipsum() +
    #theme_classic() +
  labs(
    x = "Year", 
    y = "Frequency"
    ) +
    theme()


# Turn it interactive
plot2 <- ggplotly(plot2, tooltip="text")
plot2

```

#### Sentiments over year {.tabset}
By taking a further step, we also took a look at the sentiments by the press over the past twenty years. For the three newspapers we selected, we know that Bangor Daily news could be a more conservative newspaper, since it is from the more northern part of Maine, while Portland Press Herald and Sun Journal could be more liberal. We can see Bangor Daily News almost stopped to use neither negative nor positive to describe parole after 2020, this could be because that more conservative newspaper may not be as interested in reinstating parole so they may not talk about or make judgements about parole that often.

<br/>

##### Negative adjectives and adverbs by press (count)
```{r general-negative-1, fig.align = 'left'}
parole_sub_stacked1 <- parole_text %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(sentiment == "negative") %>%
  group_by(year, pubtitle, sentiment) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sub_stacked1 %>%
  ggplot(aes(x=year, y=count, fill=pubtitle)) +
  geom_area(alpha = 0.6) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("frequency of negative adjectives or adverbs in Maine news around parole") +
  labs(subtitle = "by press") +
  theme_ipsum() +
  theme_minimal()
```

##### Positive adjectives and adverbs by press (count)
```{r general-positive-1, fig.align = 'left'}
parole_sub_stacked1 <- parole_text %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(sentiment == "positive") %>%
  group_by(year, pubtitle, sentiment) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sub_stacked1 %>%
  ggplot(aes(x=year, y=count, fill=pubtitle)) +
  geom_area(alpha = 0.6) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("frequency of positive adjectives or adverbs in Maine news around parole by press") +
  labs(subtitle = "by press") +
  theme_ipsum() +
  theme_minimal()
```

#### Sentiments over year by press {.tabset}

Since each newspaper article could have a wide range of length, it is more accurate to see the average percentage of negative adjectives and adverbs out of all adjectives and adverbs. The new graph does not seem to undermine our previous conclusions. 

<br/>

##### Negative adjectives and adverbs by press (ratio)

```{r general-positive-2, fig.align = 'left'}
parole_sub_stackedx <- parole_text %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  group_by(year, pubtitle, sentiment) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sub_wide <- parole_sub_stackedx %>%
  pivot_wider(names_from = sentiment, values_from = count)

parole_sub_stacked2 <- parole_sub_wide %>%
  mutate(percentage_positive = positive/(negative + positive + neutral)) %>%
  group_by(year, pubtitle) %>%
  arrange(desc(percentage_positive)) %>%
  na.omit()

parole_sub_stacked2 %>%
  ggplot(aes(x=year, y=percentage_positive, fill=pubtitle)) +
  geom_area(alpha = 0.6) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of positive adjectives/adverbs occurance in Maine news around parole") +
  labs(subtitle = "by press") +
  theme_ipsum() +
  theme_minimal()
```

##### Positive adjectives and adverbs by press (ratio)

```{r general-negative-2, fig.align = 'left'}
parole_sub_stackedx <- parole_text %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  group_by(year, pubtitle, sentiment) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sub_wide <- parole_sub_stackedx %>%
  pivot_wider(names_from = sentiment, values_from = count)

parole_sub_stacked2 <- parole_sub_wide %>%
  mutate(percentage_negative = negative/(negative + positive + neutral)) %>%
  group_by(year, pubtitle) %>%
  arrange(desc(percentage_negative)) %>%
  na.omit()

parole_sub_stacked2 %>%
  ggplot(aes(x=year, y=percentage_negative, fill=pubtitle)) +
  geom_area(alpha = 0.6) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of negative adjectives/adverbs occurance in Maine news around parole") +
  labs(subtitle = "by press") +
  theme_ipsum() +
  theme_minimal()
```

### Part III - Psychology Research

```{r create-filters}
parole_adult <- parole_text_title %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(word == "adult")

parole_juvenile <- parole_text_title %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(word == "juvenile" | word == "teenager")

parole_violent <- parole_text_title %>%
  filter(pos == "Adjective" | pos == "Adverb") %>%
  filter(word == "violent" | word == "violence")

parole_sub2 <- parole_sub %>%
  select(text, Title, year, pubtitle) %>%
  unnest_tokens(output = word, input = text) %>%
  anti_join(stop_words) %>%
  mutate(word = tolower(word)) 

parts_of_speech_ad <- parts_of_speech %>%
  filter(pos %in% c("Adjective", "Adverb", "Noun", "Verb"))

parole_sub2 <- parole_sub2 %>%
  left_join(parts_of_speech_ad, by = "word")

parole_sub3 <- parole_sub2 %>%
  group_by(year, Title, pubtitle, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sub4 <- parole_sub2 %>%
  group_by(Title, year, pubtitle, word, pos) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit()

parole_sentiments <- get_sentiments()
parole_adj_adv <- parole_sub4 %>%
  left_join(parole_sentiments, by = "word")
# anti_join(parole_sentiments) 

parole_adj_adv[is.na(parole_adj_adv)] <- "neutral"

```

#### Violence {.tabset}
In this next section, we replicate some of the analysis that Professor Amy Douglass and her class have done. Professor Amy Douglass is a Psychology Professor that specialize in social psychology and law, such as eyewitness identification and death penalty. In this first part, we found that newspaper articles that involve violent/violence could be associated with more frequent negative sentiments as compared to articles that do not have violent/violence mentioned. As shown in the graphs, the ratio of negative adjectives/adverbs for articles that involve “violence/violent” is higher than those without. The ratio of positive adjectives/adverbs for articles that involve “teenager/juvenile” is lower than those without.


##### Negative sentiments towards "violence/violent"
```{r violence-negative, fig.align = 'left'}
parole_violent_final <- parole_adj_adv %>%
  mutate(keywords = ifelse(Title %in% parole_violent$Title, "violent", "no-violent")) %>%
  filter(pos == "Adjective" | pos == "Adverb")

parole_violent_final <- parole_violent_final%>%
  group_by(sentiment, keywords) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit() %>%
  pivot_wider(names_from = sentiment, values_from = count) %>%
  mutate(percentage_negative = negative/(negative + positive + neutral)) 

parole_violent_final %>%
  ggplot(aes(x=keywords, y=percentage_negative, fill = keywords)) +
  geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of negative adjectives/adverbs occurance in Maine news around parole") +
  labs(x = "whether the news contain 'violent/violence'", y = "ratio") +
  theme_minimal()
```

##### Positive sentiments towards "violence/violent"
```{r violence-positive, fig.align = 'left'}
parole_violent_final <- parole_adj_adv %>%
  mutate(keywords = ifelse(Title %in% parole_violent$Title, "violent", "no-violent")) %>%
  filter(pos == "Adjective" | pos == "Adverb")

parole_violent_final <- parole_violent_final%>%
  group_by(sentiment, keywords) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit() %>%
  pivot_wider(names_from = sentiment, values_from = count) %>%
  mutate(percentage_positive = positive/(negative + positive + neutral)) 

parole_violent_final %>%
  ggplot(aes(x=keywords, y=percentage_positive, fill = keywords)) +
  geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of positive adjectives/adverbs occurance in Maine news around parole") +
  labs(x = "whether the news contain 'violent/violence'", y = "ratio") +
  theme_minimal()
```

#### juvenile {.tabset}

We also found that newspaper articles that involve juvenile or teenager could be associated with less frequent negative sentiments as compared to articles that do not have juvenile and teenager mentioned. As shown in the graphs, the ratio of negative adjectives/adverbs for articles that involve “teenager/juvenile” is lower than those without. The ratio of positive adjectives/adverbs for articles that involve “teenager/juvenile” is higher than those without.

##### Negative sentiments towards "Juvenile/teenager"
```{r juvenile-negative, fig.align = 'left'}
parole_juvenile_final <- parole_adj_adv %>%
  mutate(dummy = ifelse(Title %in% parole_juvenile$Title, "juvenile/teenager", "no-juvenile/teenager")) %>%
  filter(pos == "Adjective" | pos == "Adverb") 

parole_juvenile_final <- parole_juvenile_final%>%
  group_by(sentiment, dummy) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit() %>%
  pivot_wider(names_from = sentiment, values_from = count) %>%
  mutate(percentage_negative = negative/(negative + positive + neutral)) 

parole_juvenile_final %>%
  ggplot(aes(x=dummy, y=percentage_negative, fill = dummy)) +
  geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of negative adjectives/adverbs occurance in Maine news around parole") +
  labs(x = "whether the news contain 'juvenile/teenager'") +
  theme_minimal()
```

##### Positive sentiments towards "violence/teenager"
```{r juvenile-positive, fig.align = 'left'}
parole_juvenile_final <- parole_adj_adv %>%
  mutate(dummy = ifelse(Title %in% parole_juvenile$Title, "juvenile/teenager", "no-juvenile/teenager")) %>%
  filter(pos == "Adjective" | pos == "Adverb") 

parole_juvenile_final <- parole_juvenile_final%>%
  group_by(sentiment, dummy) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit() %>%
  pivot_wider(names_from = sentiment, values_from = count) %>%
  mutate(percentage_positive = positive/(negative + positive + neutral)) 

parole_juvenile_final %>%
  ggplot(aes(x=dummy, y=percentage_positive, fill = dummy)) +
  geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of positive adjectives/adverbs occurance in Maine news around parole") +
  labs(x = "whether the news contain 'juvenile/teenager'") +
  theme_minimal()
```

#### adult {.tabset}

For newspaper articles that involve adult, we got an ambiguous result: the ratio of negative adjectives/adverbs for articles that involve “adult” is higher than those without, but the ratio of positive adjectives/adverbs for articles that involve “adult” is also higher than those without. This could mean that parole for adult is more debatable. 

##### Negative sentiments towards "adult"
```{r adult-negative, fig.align = 'left'}
parole_adult_final <- parole_adj_adv %>%
 mutate(dummy = ifelse(Title %in% parole_adult$Title, "adult", "no-adult")) %>%
 filter(pos == "Adjective" | pos == "Adverb") 

parole_adult_final <- parole_adult_final%>%
  group_by(sentiment, dummy) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit() %>%
  pivot_wider(names_from = sentiment, values_from = count) %>%
  mutate(percentage_negative = negative/(negative + positive + neutral)) 

parole_adult_final %>%
  ggplot(aes(x=dummy, y=percentage_negative, fill = dummy)) +
  geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of negative adjectives/adverbs occurance in Maine news around parole") +
  labs(x = "whether the news contain 'adult'") +
  theme_minimal()
```

##### Positive sentiments towards "adult"
```{r adult-positive, fig.align = 'left'}
parole_adult_final <- parole_adj_adv %>%
 mutate(dummy = ifelse(Title %in% parole_adult$Title, "adult", "no-adult")) %>%
 filter(pos == "Adjective" | pos == "Adverb") 

parole_adult_final <- parole_adult_final%>%
  group_by(sentiment, dummy) %>%
  summarise(count = n())%>%
  arrange(desc(count)) %>%
  na.omit() %>%
  pivot_wider(names_from = sentiment, values_from = count) %>%
  mutate(percentage_positive = positive/(negative + positive + neutral)) 

parole_adult_final %>%
  ggplot(aes(x=dummy, y=percentage_positive, fill = dummy)) +
  geom_bar(stat="identity", position=position_dodge()) +
  scale_fill_viridis(discrete = TRUE) +
  ggtitle("ratio of positive adjectives/adverbs occurance in Maine news around parole") +
  labs(x = "whether the news contain 'adult'") +
  theme_minimal()
```


### Part IV - word association and network of words

We used word association analysis and the network of words to find the frequently appeared phrases and pairs of words. Above are two outputs generated from our codes. As indicated by the phrases “substance abuse”, “license suspended”, “domestic violence”, and “sexual assault”, these types of crimes are often discussed in news articles about parole. County names, including androscoggin county, cumberland county, and oxford county are often mentioned. “Probation” in the news is often associated with “violation”, indicating a generally negative impression towards probation. 

#### Bigram frequencies barplot for most frequent bigram phrases
```{r bigram-frequencies, fig.width=7}
data <- parole_sub

words <- unnest_tokens(data, word, text)
words <- words %>% anti_join(stop_words)
words <- unnest_tokens(data, word, text, token = "ngrams", n = 2)

words <- words %>%
  separate(word, c('word1', 'word2'))

clean_words <- words %>%
  anti_join(stop_words, by= c("word1" = "word")) %>%
  anti_join(stop_words, by= c("word2" = "word")) %>%
  filter(word1 != "pages" & word2 != "pages")

clean_words <- clean_words %>%
  unite(phrase, c("word1", "word2"), sep = " ")

bigram_counts <- clean_words %>%
  group_by(phrase) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) 

clean_words <- bigram_counts %>%
 separate(phrase, c('word1', 'word2'))

myvars <- c("word1", "word2","count")
bigram_tograph <- clean_words[myvars]

More_than_50 <- bigram_counts %>%
  filter(count >= 50) %>%
  mutate(phrase = reorder(phrase, count)) 
ggplot(More_than_50, aes(x = count, y = phrase)) +
  geom_col(fill = "#669933", colour = "black") + 
  ggtitle("Frequently appeared phrases (count >= 50)") +
  theme_minimal()
```


#### Word Association
```{r word-association, fig.width= 9, fig.height= 8}
words_network <- clean_words %>%
  filter(count >= 25) 

set.seed(2000)

words_network %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = count, edge_width = count)) +
  geom_node_point(color = "mediumpurple", size = 3) +
  geom_node_text(aes(label = name), vjust = 1.8) +
  ggtitle(expression(paste("Network of Words: Pairs of words that appeared together more than 25 times"))) +
  theme_void()
```


## Discussion & Limitations
There are a few limitations of our research that may affect the accuracy or comprehensiveness of our results. 

First of all, our primary source of data is news from Maine local newspapers from 2000 to the present. Although previous research suggested that news and media coverage are capable of influencing as well as representing public opinions, such power is limited to certain circumstances and may not be entirely accurate (McGregor, 2019; Mutz et al., 1997). Our research question is about public perceptions towards parole, so sentiment is an important aspect of our analyses. However, news may not include as much sentiments as facts due to its nature. Therefore, using merely news to analyze the sentiments and perspectives of Maine residents may not be sufficient. Moreover, how newspapers cover news may be largely affected by other factors, such as the government pressure, political orientation of the press, or profit concerns (Vanderwicken, 2014). Therefore, their coverages may not truly reflect public opinions or the truth of the news. 

Second, processing text data using our code may not be comprehensive and accurate enough. We were able to filter out most of the irrelevant information and keep as much related data as possible using R. However, due to the limit of our knowledge of R and the time limit we have, we were unable to filter out all irrelevant information without missing important data. For example, “page 30” is irrelevant, but filtering it out will also cause the loss of important information such as “30 days license suspension”. In order to process such a large amount of data, we have set certain criteria to process and clean up the data, thus it is possible that important information is filtered out because it does not qualify for such criteria. What’s more, words of the same stem were not combined together, such as violate, violation, and violation. Separating these words may affect the accuracy of our results.

## Next steps 
For further research on the public perspective of parole and probation using text analysis, we have the following suggestions. 

First, further analyses can implement stemming to minimize repeatedly counting words of the same stem. Stemming would be able to combine these words, thus providing us with a more accurate count of frequency. 

Second, researchers could apply more machine learning techniques. We were able to apply the ideas of machine learning for text analysis, such as sentiment analysis and spam filtering, using simplified methods. Due to the time limit and other restrictions, we were unable to elaborate more and build a more complete machine learning model for analyses. Future studies may continue working on implementing machine learning into text analysis for study of public opinions on parole. 

Also, Since many of our graphs are categorized and filtered by similar criteria, it would be efficient to make many of our visualizations into R-shiny app, so that the visualizations can be more interactive, flexible and comprehensive.

Furthermore, a more generalized word association may be applied. Our word association analysis is limited to words that are directly next to each other in the text. For example, only “license suspension” is included and the words “license” and “suspension” are marked as associated, but “license got suspended” is not included where “license” and “suspension” here are not considered as associated. If further study can use machine learning models to expand the range of association to the whole sentence, therefore able to analyze words that are related but are not next to each other in the texts, there might be more general results found by word association analysis. 


## Future Research
Future study may look into whether parole is advocated in Maine or other states and whether the advocacy is related to change of public opinions. Opinions from different demographics or backgrounds may also be discussed with data that include demographic information, such as age or racial differences in supportiveness of parole. Researchers can also examine people’s supportiveness of parole from the four perspectives that were proposed by PSYC 218 class: Cost of incarceration, whether victims support parole, humane treatment or not, and whether parole increases violent/non-violent crime. From our conversation with our MPAC partner, we also propose that psychology research may discuss whether or not people support parole and in different situations and scenarios, such as in a scenario where people themselves broke the law, can be as minor as speeding, and is facing the jail, verses where people are victims or survivors of crimes themselves. 

## References

[1] Benson, E., 2003. Rehabilitate or punish?. [online] https://www.apa.org. Available at: <https://www.apa.org/monitor/julaug03/rehab> [Accessed 25 May 2022].

[2] Letter to Maine Prisoner Advocacy Coalition (MPAC); Re: Parole survey data analysis; From: Professor Amy Douglass and students in Psychology 218 (Statistics) 

[3] McGregor, S. C. (2019). Social media as public opinion: How journalists use social media to represent public opinion. Journalism, 20(8), 1070–1086. https://doi.org/10.1177/1464884919845458

[4] Mutz, D. C., & Soss, J. (1997). Reading Public Opinion: The Influence of News Coverage on Perceptions of Public Sentiment. The Public Opinion Quarterly, 61(3), 431–451. http://www.jstor.org/stable/2749580

[5] Pfaff, John F. “The Complicated Economics of Prison Reform.” Michigan Law Review 114, no. 6 (2016): 951–981. https://search.informit.org/doi/10.3316/agispt.20190913016882.

[6] Vanderwicken, Peter. “Why the News Is Not the Truth.” Harvard Business Review, 1 Aug. 2014, https://hbr.org/1995/05/why-the-news-is-not-the-truth.   

[7] Watts, A., 2018. In Depth: Sentencing Guidelines and Discretionary Parole Release. [online] Robina Institute Sentencing Guidelines Resource Center. Available at: <https://sentencing.umn.edu/content/depth-sentencing-guidelines-and-discretionary-parole-release> [Accessed 25 May 2022]. 

[8] Zhang, Z. (2018). Text Mining for Social and Behavioral Research Using R: A Case Study on Teaching Evaluation. Retrievable from https://books.psychstat.org/textmining









